{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7dafe5",
   "metadata": {
    "papermill": {
     "duration": 0.006602,
     "end_time": "2022-12-06T15:31:54.678496",
     "exception": false,
     "start_time": "2022-12-06T15:31:54.671894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **DeepTweets Challenge**\n",
    "\n",
    "## Approach\n",
    "\n",
    "This challenge is about classifing new tweets by assigning labels based on an already classified dataset of tweets. There are two labels, so this is a *binary classification*. However, it is important to not that a tweet might not fit in either one and hence mislead the classification. Thus we should define a set of features that would count as a valid tweet, so that it would corelate with its label.\n",
    "\n",
    "Each tweet is basically a string representing a text. However, it might have some *properties*. Such properties may give a tweet an *extended meaning*. However, a tweet has also a *category* that reflects the importance of its properties, which *in itself is a property* of the tweet.\n",
    "\n",
    "### Tweet Properties\n",
    "\n",
    "- *Hashtags*: a string that comes after `#` e.g. `#Here #2000Here #_Test123` are valid, but `test#here #123 #a` are not\n",
    "- *Mentions*: a string that comes after `@` e.g. `@user @user123 @123_user` are valid, but `email@here.com tst@ @12` are not\n",
    "- *URLs*: twitter's shortened ones only e.g. `http://t.co/hY45Ah1A`\n",
    "\n",
    "### Tweet Categories\n",
    "\n",
    "- *reply tweet*: *starts* with `@` e.g. `@user this is good @other` is valid but `.@some good` is not\n",
    "- *retweet*: matching the pattern `RT mention:` \n",
    "   - *regular retweets* must **start** with prefix e.g. `RT @user: this is good`\n",
    "   - *quote retweets* need to only **contain** the prefix `some thing RT @user: say word`\n",
    "- *regular tweet*: is any tweet that is not in any of the other categories\n",
    "\n",
    "## Application\n",
    "\n",
    "This *binary classification* problems can be solved using the *Logistic Regression* model. But before training the model we have to turn tweets into a *mathematical model* by extracting their features.\n",
    "\n",
    "And since each tweet is composed of terms, it is [advised](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) to build one based on the frequency of each term, because it *should* reflect the importance. This also kowns as a *Bag of Words* model, which would extract the features of the tweets by turning each property into a *vector* such that close properties are adjacent.\n",
    "\n",
    "> *Each step has a section that elaborates on its implementation*\n",
    "\n",
    "### Handling the data\n",
    "1. [X] Preprocess the tweets\n",
    "   - fix encoding, remove extra whitespaces, ...\n",
    "1. [X] Filter the tweets by category\n",
    "1. [X] Process the properties of tweets\n",
    "   - such that we end up with a reduced version\n",
    "\n",
    "### Modeling the ML algorithm\n",
    "1. [X] Extract the features from the properties of the tweets\n",
    "    - using TF-IDF as *Bag of Words* model\n",
    "2. [X] Train the *Logistic Regression* model\n",
    "\n",
    "## Insights\n",
    "1. [X] Confusion Matrix\n",
    "1. [X] ROC\n",
    "1. [X] Match with reverse testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "985b9b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T15:31:54.690770Z",
     "iopub.status.busy": "2022-12-06T15:31:54.690097Z",
     "iopub.status.idle": "2022-12-06T15:32:06.505195Z",
     "shell.execute_reply": "2022-12-06T15:32:06.503436Z"
    },
    "papermill": {
     "duration": 11.824623,
     "end_time": "2022-12-06T15:32:06.508239",
     "exception": false,
     "start_time": "2022-12-06T15:31:54.683616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\r\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\r\n",
      "Collecting textsearch>=0.0.21\r\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\r\n",
      "Collecting anyascii\r\n",
      "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pyahocorasick\r\n",
      "  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\r\n",
      "Successfully installed anyascii-0.3.1 contractions-0.1.73 pyahocorasick-1.4.4 textsearch-0.0.24\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "LANGUAGE = 'english'\n",
    "ENCODING = 'latin-1'\n",
    "ENCODING_ERROR_POLICY = \"ignore\"\n",
    "\n",
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69b2ea7",
   "metadata": {
    "papermill": {
     "duration": 0.00511,
     "end_time": "2022-12-06T15:32:06.519496",
     "exception": false,
     "start_time": "2022-12-06T15:32:06.514386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> *default text encoding parameters, since it may contain non-ascii characters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b32e58e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T15:32:06.533136Z",
     "iopub.status.busy": "2022-12-06T15:32:06.532620Z",
     "iopub.status.idle": "2022-12-06T15:32:06.623362Z",
     "shell.execute_reply": "2022-12-06T15:32:06.621817Z"
    },
    "papermill": {
     "duration": 0.101018,
     "end_time": "2022-12-06T15:32:06.625941",
     "exception": false,
     "start_time": "2022-12-06T15:32:06.524923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# shuffling the data is handy when debugging large datasets\n",
    "train_df = pd.read_csv(\"../input/deeptweets/train.csv\").sample(frac=1)\n",
    "training_df = pd.read_csv(\"../input/deeptweets/training.csv\");\n",
    "\n",
    "assert train_df.size == pd.concat([train_df, training_df]).drop_duplicates().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187af04e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T15:32:06.640245Z",
     "iopub.status.busy": "2022-12-06T15:32:06.638879Z",
     "iopub.status.idle": "2022-12-06T15:32:06.653837Z",
     "shell.execute_reply": "2022-12-06T15:32:06.651991Z"
    },
    "papermill": {
     "duration": 0.024737,
     "end_time": "2022-12-06T15:32:06.656845",
     "exception": false,
     "start_time": "2022-12-06T15:32:06.632108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TweetId      0\n",
       "Label        0\n",
       "TweetText    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5039d58f",
   "metadata": {
    "papermill": {
     "duration": 0.005281,
     "end_time": "2022-12-06T15:32:06.668642",
     "exception": false,
     "start_time": "2022-12-06T15:32:06.663361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> *Training data has no missing values*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee38440",
   "metadata": {
    "papermill": {
     "duration": 0.00542,
     "end_time": "2022-12-06T15:32:06.679603",
     "exception": false,
     "start_time": "2022-12-06T15:32:06.674183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Word Lemmatization\n",
    "\n",
    "The idea is to reduce each Tweet into a *subset of words which only contains the very critical words*.\n",
    "\n",
    "Such words would **eventually** correlate with its label. even more, by using the concept of [Lemmatization](https://www.researchgate.net/publication/348306833_An_Interpretation_of_Lemmatization_and_Stemming_in_Natural_Language_Processing) we ensure that words would be in their root form.\n",
    "\n",
    "> *Idea: Sort of getting a signature of the Tweet based on which the words it is composed of*. This also contains the hash-signature of the URL, if the Tweet has one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0181adce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T15:32:06.693547Z",
     "iopub.status.busy": "2022-12-06T15:32:06.693167Z",
     "iopub.status.idle": "2022-12-06T15:32:19.456708Z",
     "shell.execute_reply": "2022-12-06T15:32:19.455714Z"
    },
    "papermill": {
     "duration": 12.774563,
     "end_time": "2022-12-06T15:32:19.459725",
     "exception": false,
     "start_time": "2022-12-06T15:32:06.685162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VIDEO: In case you missed it- British Tennis players do the Harlem Shake http://t.co/jVCeZMn6CS #harlemshake RT &amp; share!' \n",
      " ' video : case miss it- british tennis player harlem shake http://t.co/jvcezmn6cs # harlemshake rt & amp ; share ! '\n",
      "\n",
      "'#WeDemandAVote for them: http://t.co/8oyTD7XF' \n",
      " ' # wedemandavote : http://t.co/8oytd7xf '\n",
      "\n",
      "'#Cybercrime &amp; #cybersecurity discussions with @Europol_EU &amp; @enisa_eu in @EP_justice from 3pm CET http://t.co/ImUNp9Z0' \n",
      " ' # cybercrime & amp ; # cybersecurity discussion @europol_eu & amp ; @enisa_eu @ep_justice 3 pm cet http://t.co/imunp9z0 '\n",
      "\n",
      "'RT @CapitalOne_Cup: RT by 9am tomorrow for a chance to win a special #CapitalOneCup Final @MitreSports ball! T&amp;Cs http://t.co/jUt0Ir ...' \n",
      " ' rt @capitalone_cup : rt 9 tomorrow chance win special # capitalonecup final @mitresports ball ! t&amp;cs http://t.co/jut0ir ... '\n",
      "\n",
      "'Want to know what goes on under the shell of an #F1 car? @CamsCorner lifts the lid http://t.co/cci8wqtn #AusGP' \n",
      " ' want know # f1 car ? @camscorner lift lid http://t.co/cci8wqtn # ausgp '\n",
      "\n",
      "'@avatar81 See the previous tweet Dan - Aston Villa &amp; Everton.' \n",
      " ' @avatar81 previous tweet dan - aston villa & amp ; everton . '\n",
      "\n",
      "'2 February 1990 President FW de Klerk announces that the ANC would be legalised and that #NelsonMandela would be released from prison' \n",
      " ' 2 february 1990 president fw de klerk announce anc legalise # nelsonmandela release prison '\n",
      "\n",
      "'RT @USAIDGH: .@USAIDGH #HIV prev prog strike balance btwn biomedical &amp; behavior change re @theIOM report http://t.co/cfuDq7Yh3y #PEP ...' \n",
      " ' rt @usaidgh : .@usaidgh # hiv prev prog strike balance btwn biomedical & amp ; behavior change @theiom report http://t.co/cfudq7yh3y # pep ... '\n",
      "\n",
      "'Sorry for the long absence. Tweeting will begin regularly as from this evening.' \n",
      " ' sorry long absence . tweeting begin regularly evening . '\n",
      "\n",
      "'HM: PM has announced Rs 2 lakh ex-gratia for the deceased, and Rs. 50,000 to injured persons in # Hy\\u2019bad blasts' \n",
      " ' hm : pm announce r 2 lakh ex - gratia deceased , r . 50,000 injure person # hy\\u2019bad blast '\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import contractions\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# reduce words into their common root form would improve the accuracy of IF-IDF model\n",
    "# however, it may require additional processing to ensure the quality of the outcome\n",
    "def lemmatise(text):\n",
    "    text = ' '.join([contractions.fix(w) for w in text.split()])\n",
    "    text = nlp(text)\n",
    "    tokens = []\n",
    "    for w in text:\n",
    "        if w.lemma_.lower() not in nlp.Defaults.stop_words:\n",
    "            tokens.append(w.lemma_.lower())\n",
    "    return tokens\n",
    "\n",
    "for row in train_df.head(10).iloc:\n",
    "    lem = lemmatise(row.TweetText)\n",
    "    ss = ' '.join(lem)\n",
    "    print(row.TweetText, \"\\n\", ss)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5833bafa",
   "metadata": {
    "papermill": {
     "duration": 0.005844,
     "end_time": "2022-12-06T15:32:19.471805",
     "exception": false,
     "start_time": "2022-12-06T15:32:19.465961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train on news data\n",
    "\n",
    "1. read news based on category\n",
    "2. lemmatise the news \n",
    "3. train a bais model \n",
    "3. when reading tweet words, favour words with high bais "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ac85e4",
   "metadata": {
    "papermill": {
     "duration": 0.005551,
     "end_time": "2022-12-06T15:32:19.483053",
     "exception": false,
     "start_time": "2022-12-06T15:32:19.477502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tweet properties\n",
    "\n",
    "Are any combination of: words, mentions, hashtags, urls and dates/years. However, since properties are not taken into account for all tweets equally, we need to explicitly filter the tweets by category to pick correct information. \n",
    "\n",
    "> For example, arguably, no need to cosider words in a reply as oppose to a quote retweet. Urls and dates are extracted from all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f86c9861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T15:32:19.497797Z",
     "iopub.status.busy": "2022-12-06T15:32:19.497172Z",
     "iopub.status.idle": "2022-12-06T15:32:19.551163Z",
     "shell.execute_reply": "2022-12-06T15:32:19.549866Z"
    },
    "papermill": {
     "duration": 0.064385,
     "end_time": "2022-12-06T15:32:19.553803",
     "exception": false,
     "start_time": "2022-12-06T15:32:19.489418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'@HolterMedia See ya next year Petey ;)'\n",
      "\n",
      "391316414f838aa175381a687910ba27  holtermedia ya year petey holter medium\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import calendar\n",
    "import dateutil.parser as date_parser\n",
    "from hashlib import md5\n",
    "\n",
    "# compiling regular expressions because they will be exhaustively used\n",
    "url_re = re.compile(r\"\\s?htt(.*?)(\\s|$)\")\n",
    "tco_url_re = re.compile(r'https?://t.co/([\\w]{6,15})')\n",
    "mention_re = re.compile(r'[^\\w]*@(\\d*[a-zA-Z_][\\w]*)')\n",
    "hashtag_re = re.compile(r'[^\\w]*#(\\d*[a-zA-Z_][\\w]*)')\n",
    "reply_re = re.compile(r\"^(@[\\w]+\\s)*\")\n",
    "quote_re = re.compile(r\"^(.*?) (RT @[\\w]+: .*)$\")\n",
    "rt_re = re.compile(r\"^RT @[\\w]+: (.*)$\")\n",
    "part_re = re.compile(r\"([A-Z]+[a-z0-9]*)\")\n",
    "vs_suffix_re = re.compile(r'(v[s]?)$')                            # v or vs suffix as in FoovBar FoovsBar\n",
    "s_suffix = re.compile(r'[^\\w\\s][sS]')                             # 's suffix as in who's\n",
    "ponct_re = re.compile(r'[^\\w\\s]+')                                # non(characters or whitespace)\n",
    "num_re = re.compile(r'\\b\\d+\\b')                                   # only standalone numbers\n",
    "\n",
    "# credits: https://stackoverflow.com/a/51123164\n",
    "full_months = [month for month in calendar.month_name if month]\n",
    "short_months = [d[:3] for d in full_months]\n",
    "months = '|'.join(short_months + full_months)\n",
    "sep = r'[.,/]?\\s+'               # seperator\n",
    "day = r'\\d+'\n",
    "year = r'\\d+'\n",
    "day_or_year = r'\\d+(?:\\w+)?'\n",
    "date_re = re.compile(rf'(?:{day}{sep})?(?:{months}){sep}{day_or_year}(?:{sep}{year})?')\n",
    "year_only_re = re.compile(r\"(^|[\\s\\b])([12][890][\\d]{2})([\\s\\b]|$)\")\n",
    "\n",
    "def parse_date(s):\n",
    "    try:\n",
    "        return date_parser.parse(s).date()\n",
    "    except:\n",
    "        print(\"`{}` could not be parse as date\".format(s))\n",
    "        pass\n",
    "\n",
    "class TweetProperties(object):\n",
    "    # takes a `text' representing the content, and then booleans to indicate extract methods\n",
    "    def __init__(self, text=\"\", words=False, mentions=False, hashtags=False, usehash=False):\n",
    "        self.text = text\n",
    "        self.texthash = [md5(text.encode(ENCODING)).hexdigest()] if usehash else []\n",
    "        self.urls = []\n",
    "        \n",
    "        self.prop_words = words\n",
    "        self.words = []  \n",
    "        self.extended_words = []\n",
    "        \n",
    "        self.prop_mentions = mentions\n",
    "        self.mentions = []\n",
    "        \n",
    "        self.prop_hashtags = hashtags\n",
    "        self.hashtags = []\n",
    "        \n",
    "        self.dates = []\n",
    "        self.years = []\n",
    "        if len(self.text) != 0:\n",
    "            self.process()\n",
    "\n",
    "    def __str__(self):\n",
    "        split_date = lambda d: str(d) #' '.join(str(d).split('-'))\n",
    "        return (\n",
    "            ' '.join(self.texthash) + \" \" + ' '.join(self.urls) + \" \" +\n",
    "            ' '.join(\n",
    "                [w for w in self.mentions + self.hashtags + self.words + list(set(self.extended_words)) if len(w) > 1] +\n",
    "#                 [split_date(parse_date(y).replace(month=1, day=1)) for _, y, _ in self.years] +\n",
    "                [str(y) for y in self.years] +\n",
    "#                 [split_date(parse_date(d)) for d in self.dates]\n",
    "                [str(d) for d in self.dates]\n",
    "            ).lower()\n",
    "        )\n",
    "\n",
    "    def words_bag(self):\n",
    "        return self.hashtags + self.words + self.extended_words\n",
    "\n",
    "    # Since tweets can be embedded, this allows the extensions of properties\n",
    "    def append(self, props):\n",
    "        self.texthash += props.texthash\n",
    "        self.words += props.words\n",
    "        self.urls += props.urls\n",
    "        self.mentions += props.mentions\n",
    "        self.hashtags += props.hashtags\n",
    "        self.dates += props.dates\n",
    "        self.years += props.years\n",
    "        self.extended_words += props.extended_words\n",
    "\n",
    "    def extract_urls(self):\n",
    "        self.urls = re.findall(tco_url_re, self.text)\n",
    "        self.text = re.sub(url_re, \" \", self.text)                     # extract       \n",
    "\n",
    "    def extract_words(self):\n",
    "        if not self.prop_words:\n",
    "            return\n",
    "        self.text = re.sub(s_suffix, ' ', self.text)                        \n",
    "        self.text = re.sub(ponct_re, ' ', self.text)                       \n",
    "        self.text = re.sub(num_re, ' ', self.text)\n",
    "        for w in lemmatise(self.text):\n",
    "            self.words.append(w) #+ list(syns)\n",
    "\n",
    "    # extend word composions (LikeThis => Like)\n",
    "    def extend_word_combinations(self, word_list):\n",
    "        parts = []\n",
    "        for tag in word_list:\n",
    "            parts += re.findall(part_re, tag)\n",
    "\n",
    "        lower = lambda lst: list(map(lambda tag: tag.lower(), lst))\n",
    "        word_list = lower(word_list)\n",
    "        parts = [w.lower() for w in lemmatise(' '.join(parts))]\n",
    "        for word in parts:\n",
    "            word = re.sub(vs_suffix_re, ' ', word)       \n",
    "            if word not in word_list:\n",
    "                self.extended_words.append(word)\n",
    "\n",
    "    def extract_mentions(self):\n",
    "        if self.prop_mentions:\n",
    "            self.mentions = re.findall(mention_re, self.text)    \n",
    "            self.extend_word_combinations(self.mentions)\n",
    "        self.text = re.sub(mention_re, ' ', self.text)               # extract anyway\n",
    "\n",
    "    def extract_hashtags(self):\n",
    "        if self.prop_hashtags:\n",
    "            self.hashtags = re.findall(hashtag_re, self.text)       \n",
    "            self.extend_word_combinations(self.hashtags)\n",
    "        self.text = re.sub(hashtag_re, ' ', self.text)               # extract anyway\n",
    "\n",
    "    def extract_dates(self):\n",
    "#         self.dates = re.findall(date_re, self.text)\n",
    "        self.dates = [parse_date(d) for d in re.findall(date_re, self.text)]\n",
    "        self.text = re.sub(date_re, \" \", self.text)\n",
    "#         self.years = re.findall(year_only_re, self.text)\n",
    "#         self.years = [parse_date(y).replace(month=1, day=1) for _, y, _ in re.findall(year_only_re, self.text)]\n",
    "        self.text = re.sub(year_only_re, \" \", self.text)\n",
    "\n",
    "    def process(self):\n",
    "        # order does not matter for any of those because each one has a clean pattern\n",
    "        self.extract_urls()\n",
    "        self.extract_mentions()\n",
    "        self.extract_hashtags()\n",
    "        self.extract_dates()\n",
    "        self.text = re.sub(r\"[\\s]+\", \" \", self.text.strip())\n",
    "        # however, words would be lemmatized so the are the last to be extracted\n",
    "        self.extract_words()\n",
    "\n",
    "# since they can be stacked with quote retweets, the last retweet contains the actual tweet\n",
    "# that has been retweeted, so it is handeled as regular tweets, unless it is a reply\n",
    "#   - e.g. `RT @user1: RT @user2: this is a quote RT @user3: this is a tweet`\n",
    "class Tweet(TweetProperties):\n",
    "    def __init__(self, text):\n",
    "        super().__init__()\n",
    "\n",
    "        last = text\n",
    "        while True:\n",
    "            m = re.match(rt_re, last)\n",
    "            while m is not None:\n",
    "                last = m.group(1)\n",
    "                m = re.match(rt_re, last)\n",
    "\n",
    "            m = re.match(quote_re, last)\n",
    "            if m is not None:\n",
    "                self.process_quote(m.group(1))\n",
    "                last = m.group(2)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        self.process_quote(last)\n",
    "\n",
    "    def process_quote(self, quote):\n",
    "        if quote.startswith('@'):\n",
    "            self.append(TweetProperties(re.sub(reply_re, \" \", quote), hashtags=True, mentions=True))\n",
    "        else:\n",
    "            self.append(TweetProperties(quote, words=True, hashtags=True, mentions=True, usehash=True))  \n",
    "\n",
    "for s in train_df[train_df.TweetId == 295566866284417024].iloc:\n",
    "    print(s.TweetText)\n",
    "    print()\n",
    "    print(Tweet(s.TweetText))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4329c5",
   "metadata": {
    "papermill": {
     "duration": 0.00596,
     "end_time": "2022-12-06T15:32:19.565944",
     "exception": false,
     "start_time": "2022-12-06T15:32:19.559984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Further enhancement\n",
    "\n",
    "- fix orthograph mistakes\n",
    "- expand abbreviations\n",
    "- detect patterns\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e578470",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T15:32:19.579146Z",
     "iopub.status.busy": "2022-12-06T15:32:19.578771Z",
     "iopub.status.idle": "2022-12-06T15:32:19.590086Z",
     "shell.execute_reply": "2022-12-06T15:32:19.589231Z"
    },
    "papermill": {
     "duration": 0.020505,
     "end_time": "2022-12-06T15:32:19.592310",
     "exception": false,
     "start_time": "2022-12-06T15:32:19.571805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  305275936465641472 Sports     'VIDEO: In case you missed it- British Tennis players do the Harlem Shake http://t.co/jVCeZMn6CS #harlemshake RT &amp; share!'\n",
      "  304319182630162432 Politics   '#WeDemandAVote for them: http://t.co/8oyTD7XF'\n",
      "  304221853910720513 Politics   '#Cybercrime &amp; #cybersecurity discussions with @Europol_EU &amp; @enisa_eu in @EP_justice from 3pm CET http://t.co/ImUNp9Z0'\n",
      "  305608034414108672 Sports     'RT @CapitalOne_Cup: RT by 9am tomorrow for a chance to win a special #CapitalOneCup Final @MitreSports ball! T&amp;Cs http://t.co/jUt0Ir ...'\n",
      "  301507964957777921 Sports     'Want to know what goes on under the shell of an #F1 car? @CamsCorner lifts the lid http://t.co/cci8wqtn #AusGP'\n",
      "  306778809363988480 Sports     '@avatar81 See the previous tweet Dan - Aston Villa &amp; Everton.'\n",
      "  297601154513260544 Politics   '2 February 1990 President FW de Klerk announces that the ANC would be legalised and that #NelsonMandela would be released from prison'\n",
      "  306481132000665600 Politics   'RT @USAIDGH: .@USAIDGH #HIV prev prog strike balance btwn biomedical &amp; behavior change re @theIOM report http://t.co/cfuDq7Yh3y #PEP ...'\n",
      "  125182199732506624 Sports     'Sorry for the long absence. Tweeting will begin regularly as from this evening.'\n",
      "  304884548787924992 Politics   'HM: PM has announced Rs 2 lakh ex-gratia for the deceased, and Rs. 50,000 to injured persons in # Hy\\u2019bad blasts'\n",
      "  293241392724054017 Politics   A 'Ticket to Bollywood ' in Moscow http://t.co/7M6OayfQ\n",
      "  296819658290511872 Sports     '@talkradiojulie hahaha ;-) thanks.'\n",
      "  304738126771941377 Sports     '3x @memphistennis champ @TommyHaas13 talks about success at event and local restaurant scene in our Q&amp;A. http://t.co/uj5Qy93isl #atp #tennis'\n",
      "  301519083696967680 Politics   RT @CFR_org: How the United States can adapt to the new era of #manufacturing: http://t.co/NgraUCWI From CFR's @RenewingAmerica initiati ...\n",
      "  291511754998042624 Sports     'SIX! Crucial strike by Voges! Game on now. Bird to continue. 1-38 (5) #BBL02 #bigfinals'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 15\n",
    "\n",
    "def sample_tweets(df=train_df, size=SAMPLE_SIZE, header=None, footer=\"\",\n",
    "                  parse=lambda row: \"{:10} {}\".format(row[\"Label\"], row[\"TweetText\"])):\n",
    "    if header is not None:\n",
    "        print(header)\n",
    "    size = min(df.size, size)\n",
    "    for s in df.head(size).iloc:\n",
    "        print(\"{:20} {}\".format(s[\"TweetId\"], parse(s)))\n",
    "    if footer is not None:\n",
    "        print(footer)\n",
    "\n",
    "sample_tweets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d8abe",
   "metadata": {
    "papermill": {
     "duration": 0.006585,
     "end_time": "2022-12-06T15:32:19.605761",
     "exception": false,
     "start_time": "2022-12-06T15:32:19.599176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Processing the tweets\n",
    "\n",
    "Sparate tweets based on their category, then process each one and finally combine everyrhing again. \n",
    "\n",
    "> *this may be just a work around, and there would actually be a straight forward approach*\n",
    "\n",
    "However, tweets *may contain unicode characters*, as well as some surrounding quotes which would mess up with results. So, before anything, we should preprocess all tweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2492610f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T15:32:19.620468Z",
     "iopub.status.busy": "2022-12-06T15:32:19.620053Z",
     "iopub.status.idle": "2022-12-06T15:32:19.626506Z",
     "shell.execute_reply": "2022-12-06T15:32:19.625792Z"
    },
    "papermill": {
     "duration": 0.01599,
     "end_time": "2022-12-06T15:32:19.628199",
     "exception": false,
     "start_time": "2022-12-06T15:32:19.612209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import html\n",
    "import string\n",
    "\n",
    "extra_ws_re = re.compile(r\"\\s+\")\n",
    "surr_quotes_re = re.compile(r\"^'(.*)'$\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.encode(ENCODING, errors=ENCODING_ERROR_POLICY) \\\n",
    "        .decode('unicode_escape', errors=ENCODING_ERROR_POLICY)    # decode unicode characters\n",
    "    text = ''.join([c for c in text if c in string.printable])                # remove non-printable characters    \n",
    "    text = html.unescape(text)                                                # decode HTML characters\n",
    "    \n",
    "    text = re.sub(extra_ws_re, \" \", text)                                          # remove extra whitespaces\n",
    "    tmp = re.findall(surr_quotes_re, text)                                       # some Tweets have outter quotes\n",
    "    if tmp:\n",
    "        text = tmp[0]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a2ca8",
   "metadata": {
    "papermill": {
     "duration": 0.005746,
     "end_time": "2022-12-06T15:32:19.640146",
     "exception": false,
     "start_time": "2022-12-06T15:32:19.634400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Idea to select words\n",
    "\n",
    "1. TweetText -> TweetWords\n",
    "2. stack TweetWords per Label\n",
    "2. pick unique words per Label\n",
    "3. plot results\n",
    "\n",
    "## Idea to find relevant retweets\n",
    "1. hash tweets\n",
    "2. embed hash in retweets\n",
    "\n",
    "## Idea to extend meaning with synonyms\n",
    "1. when lemmatising take pos tag\n",
    "2. only append word with same pos tag\n",
    "\n",
    "## Idea exten meaning of composed words\n",
    "1. try to match all words agains other words\n",
    "1. if found, split by the match\n",
    "> worldcup -> world cup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc38b4",
   "metadata": {
    "papermill": {
     "duration": 0.005659,
     "end_time": "2022-12-06T15:32:19.652216",
     "exception": false,
     "start_time": "2022-12-06T15:32:19.646557",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> *This phase basically ensures that we are dealing with genuine text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3258401e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T15:32:19.665762Z",
     "iopub.status.busy": "2022-12-06T15:32:19.665139Z",
     "iopub.status.idle": "2022-12-06T15:33:15.818959Z",
     "shell.execute_reply": "2022-12-06T15:33:15.817683Z"
    },
    "papermill": {
     "duration": 56.171353,
     "end_time": "2022-12-06T15:33:15.829344",
     "exception": false,
     "start_time": "2022-12-06T15:32:19.657991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  305275936465641472 Sports VIDEO: In case you missed it- British Tennis players do the Harlem Shake http://t.co/jVCeZMn6CS #harlemshake RT & share! -> [4e50a1a8442fc4f514ce16c0bb4b51a4 jVCeZMn6CS harlemshake video case miss british tennis player harlem shake rt share]\n",
      "  304319182630162432 Politics #WeDemandAVote for them: http://t.co/8oyTD7XF -> [f152f1f8cdbdd3482adf36c738d4bba1 8oyTD7XF wedemandavote demand avote]\n",
      "  304221853910720513 Politics #Cybercrime & #cybersecurity discussions with @Europol_EU & @enisa_eu in @EP_justice from 3pm CET http://t.co/ImUNp9Z0 -> [20ccc8fbf4be7a66dc979be8084e3d91 ImUNp9Z0 europol_eu enisa_eu ep_justice cybercrime cybersecurity discussion pm cet ep europol eu]\n",
      "  305608034414108672 Sports RT @CapitalOne_Cup: RT by 9am tomorrow for a chance to win a special #CapitalOneCup Final @MitreSports ball! T&Cs http://t.co/jUt0Ir ... -> [ef4679c4b481827df7ae5f9775b51638 jUt0Ir mitresports capitalonecup rt tomorrow chance win special final ball cs sports mitre capital cup]\n",
      "  301507964957777921 Sports Want to know what goes on under the shell of an #F1 car? @CamsCorner lifts the lid http://t.co/cci8wqtn #AusGP -> [72ec52280e27b6a3e6d67d25876af303 cci8wqtn camscorner f1 ausgp want know car lift lid aus corner gp cams]\n",
      "  306778809363988480 Sports @avatar81 See the previous tweet Dan - Aston Villa & Everton. -> [  ]\n",
      "  297601154513260544 Politics 2 February 1990 President FW de Klerk announces that the ANC would be legalised and that #NelsonMandela would be released from prison -> [f45d1eb564cde2d2377dd074d3515073  nelsonmandela president fw de klerk announce anc legalise release prison nelson mandela 1990-02-02]\n",
      "  306481132000665600 Politics RT @USAIDGH: .@USAIDGH #HIV prev prog strike balance btwn biomedical & behavior change re @theIOM report http://t.co/cfuDq7Yh3y #PEP ... -> [77015490f85d3842e5cd09a4065c848c cfuDq7Yh3y usaidgh theiom hiv pep prev prog strike balance btwn biomedical behavior change report iom hi ]\n",
      "  125182199732506624 Sports Sorry for the long absence. Tweeting will begin regularly as from this evening. -> [dda99561059e237ed12b6dc80bde19c5  sorry long absence tweeting begin regularly evening]\n",
      "  304884548787924992 Politics HM: PM has announced Rs 2 lakh ex-gratia for the deceased, and Rs. 50,000 to injured persons in # Hybad blasts -> [e1d16e8da94d7d675b4b370172683637  hm pm announce rs lakh ex gratia deceased injure person hybad blast]\n",
      "  293241392724054017 Politics A 'Ticket to Bollywood ' in Moscow http://t.co/7M6OayfQ -> [846a84f5e7f49e6129b21007bc1e389b 7M6OayfQ ticket bollywood moscow]\n",
      "  296819658290511872 Sports @talkradiojulie hahaha ;-) thanks. -> [  ]\n",
      "  304738126771941377 Sports 3x @memphistennis champ @TommyHaas13 talks about success at event and local restaurant scene in our Q&A. http://t.co/uj5Qy93isl #atp #tennis -> [c46ff4582541f0e082d94b3ed8a691e8 uj5Qy93isl memphistennis tommyhaas13 atp tennis 3x champ talk success event local restaurant scene tommy haas13]\n",
      "  301519083696967680 Politics RT @CFR_org: How the United States can adapt to the new era of #manufacturing: http://t.co/NgraUCWI From CFR's @RenewingAmerica initiati ... -> [08a3acafa5dc0ef4b81c8577778aef6f NgraUCWI renewingamerica manufacturing united states adapt new era cfr initiati renew america]\n",
      "  291511754998042624 Sports SIX! Crucial strike by Voges! Game on now. Bird to continue. 1-38 (5) #BBL02 #bigfinals -> [fe29143e7176ea0e3f0a53ea9248177e  bbl02 bigfinals crucial strike voges game bird continue]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "\n",
    "pd.options.mode.chained_assignment = None # false warning\n",
    "\n",
    "def process_tweets(df, log=True):\n",
    "    df[\"TweetText\"] = df[\"TweetText\"].apply(preprocess_text)\n",
    "    df[\"TweetWords\"] = df.TweetText.apply(lambda text: str(Tweet(text)))\n",
    "    \n",
    "    if log:\n",
    "        sample_tweets(df, parse=lambda row: \"{} {} -> [{}]\".format(row.Label, row.TweetText, row.TweetWords))\n",
    "    return df\n",
    "\n",
    "train_df = process_tweets(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73420e95",
   "metadata": {
    "papermill": {
     "duration": 0.006076,
     "end_time": "2022-12-06T15:33:15.842160",
     "exception": false,
     "start_time": "2022-12-06T15:33:15.836084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Classification Model\n",
    "\n",
    "## Building a model\n",
    "\n",
    "After reducing tweets into bare words/tokens, we can actually turn each tweet into a vector. \n",
    "\n",
    "However, vector clustering is relative tothe *quality* of the frequent tokens in each tweet, and how accurate they coorelate with the label. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08a253a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T15:33:15.856169Z",
     "iopub.status.busy": "2022-12-06T15:33:15.855790Z",
     "iopub.status.idle": "2022-12-06T15:45:10.798217Z",
     "shell.execute_reply": "2022-12-06T15:45:10.796726Z"
    },
    "papermill": {
     "duration": 714.958968,
     "end_time": "2022-12-06T15:45:10.807265",
     "exception": false,
     "start_time": "2022-12-06T15:33:15.848297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 10 candidates, totalling 500 fits\n",
      "Best Score:  0.9878052675634399\n",
      "Best Params: {'ensemble__bnb__alpha': 5.777777777777778,\n",
      " 'ensemble__bnb__fit_prior': True,\n",
      " 'ensemble__lgreg__C': 340.0,\n",
      " 'ensemble__lgreg__max_iter': 100,\n",
      " 'ensemble__lgreg__penalty': 'l2',\n",
      " 'ensemble__lgreg__solver': 'liblinear',\n",
      " 'ensemble__rndf__max_depth': 20,\n",
      " 'ensemble__rndf__min_samples_leaf': 2,\n",
      " 'ensemble__rndf__min_samples_split': 10,\n",
      " 'ensemble__rndf__n_estimators': 300,\n",
      " 'tfidf__norm': 'l2',\n",
      " 'tfidf__use_idf': True,\n",
      " 'vect__max_df': 1.0,\n",
      " 'vect__max_features': 10000,\n",
      " 'vect__ngram_range': (1, 1),\n",
      " 'vect__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from warnings import simplefilter\n",
    "if not sys.warnoptions:\n",
    "    simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pprint import pprint\n",
    "\n",
    "X, y = train_df.TweetWords, train_df.Label\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=.2, stratify=y\n",
    ")\n",
    "\n",
    "clf_pipe = Pipeline([\n",
    "    (\"vect\", CountVectorizer()),\n",
    "    (\"tfidf\", TfidfTransformer()),\n",
    "    ('ensemble', VotingClassifier(\n",
    "        voting='soft',\n",
    "        estimators=[\n",
    "            ('bnb', BernoulliNB()),\n",
    "            ('lgreg', LogisticRegression()),\n",
    "            ('rndf', RandomForestClassifier())\n",
    "        ]\n",
    "    ))\n",
    "])\n",
    "\n",
    "clf_params = {\n",
    "    'vect__stop_words': ['english'],\n",
    "    \"vect__max_df\": [0.5, 1.0],\n",
    "    'vect__max_features': (5000, 10000),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2)),\n",
    "    'tfidf__use_idf': [False, True],\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'ensemble__bnb__alpha': np.linspace(0.5, 10, 10),\n",
    "    'ensemble__bnb__fit_prior': [True, False],\n",
    "    'ensemble__lgreg__max_iter': (100, 1000),\n",
    "    'ensemble__lgreg__solver': ['liblinear'],\n",
    "    'ensemble__lgreg__penalty': ['l1', 'l2'],\n",
    "    'ensemble__lgreg__C': np.linspace(10, 1000, 10),\n",
    "    'ensemble__rndf__max_depth': [10, 20],\n",
    "    'ensemble__rndf__min_samples_leaf': [2, 4],\n",
    "    'ensemble__rndf__min_samples_split': [5, 10],\n",
    "    'ensemble__rndf__n_estimators': [300, 600],\n",
    "}\n",
    "\n",
    "rsf = RepeatedStratifiedKFold()\n",
    "clf = RandomizedSearchCV(clf_pipe, clf_params, scoring='roc_auc', verbose=1, cv=rsf)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Score: \", clf.best_score_)\n",
    "print(\"Best Params: \", end=\"\")\n",
    "pprint(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4209a427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T15:45:10.822009Z",
     "iopub.status.busy": "2022-12-06T15:45:10.821527Z",
     "iopub.status.idle": "2022-12-06T15:45:11.859522Z",
     "shell.execute_reply": "2022-12-06T15:45:11.858129Z"
    },
    "papermill": {
     "duration": 1.04913,
     "end_time": "2022-12-06T15:45:11.863204",
     "exception": false,
     "start_time": "2022-12-06T15:45:10.814074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Politics       1.00      0.94      0.97      2560\n",
      "      Sports       0.94      1.00      0.97      2660\n",
      "\n",
      "    accuracy                           0.97      5220\n",
      "   macro avg       0.97      0.97      0.97      5220\n",
      "weighted avg       0.97      0.97      0.97      5220\n",
      "\n",
      "score train: 1.0 test: 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f14b8d0ab50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predict = clf.predict(X_train)\n",
    "\n",
    "print(\"{}\\nscore train: {:.2} test: {:.2}\".format(\n",
    "    classification_report(y_train, y_predict),\n",
    "    clf.score(X_train, y_train), clf.score(X_test, y_test)\n",
    "))\n",
    "\n",
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix(y_train, y_predict, normalize='pred'),\n",
    "    display_labels=[\"Politics\", \"Sports\"], \n",
    ").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d82aa6",
   "metadata": {
    "papermill": {
     "duration": 0.006664,
     "end_time": "2022-12-06T15:45:11.876997",
     "exception": false,
     "start_time": "2022-12-06T15:45:11.870333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predecting the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7b94c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T15:45:11.893558Z",
     "iopub.status.busy": "2022-12-06T15:45:11.892372Z",
     "iopub.status.idle": "2022-12-06T15:45:33.388349Z",
     "shell.execute_reply": "2022-12-06T15:45:33.387358Z"
    },
    "papermill": {
     "duration": 21.507658,
     "end_time": "2022-12-06T15:45:33.391485",
     "exception": false,
     "start_time": "2022-12-06T15:45:11.883827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`7 Feb, 10amEST` could not be parse as date\n",
      "  306486520121012224 Sports     28. The home side threaten again through Mason Bennett after he gets on the end of a long, long throw and stabs a yard wide.\n",
      "  286353402605228032 Sports     @mrbrown @aulia Thx for asking. See http://t.co/yGJePjkf. It derives from a series of abbreviations for pound avoirdupois, a unit of mass.\n",
      "  289531046037438464 Sports     @Sochi2014 construction along the shores of the Black Sea http://t.co/8dVIn7wJ\n",
      "  306451661403062273 Politics   #SecKerrys remarks after meeting with Foreign Minister Westerwelle. Transcript: http://t.co/B2J8GGfxhP | Video: http://t.co/4Qx0FhYpmP\n",
      "  297941800658812928 Sports     The #IPLauction has begun. Ricky Ponting is the first player to go under the hammer. He goes to Mumbai Indians for base price of USD 400,000\n",
      "  305722428531802112 Sports     Viswanathan Anand draws with Fabiano Caruana at Zurich http://t.co/35gG3Nw8gn\n",
      "  304713516256997377 Sports     Have your say on tonight's game - send a text to 81892 (start with 'KOP'), tweet us @LFCTV or email lfctv@liverpoolfc.com\n",
      "  234999630725783553 Politics   The #olympics may be over, but the #paralympics are about to begin. Be sure to follow @Paralympic for all the latest updates and photos!\n",
      "  303712268372283392 Sports     @richaanirudh big compliment, thanks!\n",
      "  304215754130194432 Sports     Espargar @PolEspargaro quickest as Jerez day two gets off to slow start http://t.co/cUBrD27Q #Moto2\n",
      "  305498714527633408 Politics   Spokesperson Nuland: Attacks on Aleppo are latest demonstration of Syrian regime's lack of compassion for the people it claims to represent.\n",
      "  302482560242565120 Politics   RT @ibnlive: World View: Will the next Pope be from Africa? http://t.co/GYezQVb8\n",
      "  305496375985070080 Politics   New on #DipNote: Find out how #OSCE training enhances efforts to combat illicit networks in Central Asia. http://t.co/yqhgyogjVp\n",
      "  305562747888865280 Politics   #UNSG Ban Ki-moon & Foreign Minister of Central African Republic in Addis @_AfricanUnion. http://t.co/MRo5lfTNFD\n",
      "  302124227975335937 Politics   According to @EnryBorghi, @ValeYellow46 is working to be no1 again http://t.co/4xAITf38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../input/deeptweets/test.csv\")\n",
    "test_df = process_tweets(test_df, log=False)\n",
    "\n",
    "test_df[\"Label\"] = clf.predict(test_df[\"TweetWords\"])\n",
    "\n",
    "sample_tweets(test_df)\n",
    "\n",
    "results = test_df[[\"TweetId\", \"Label\"]].reset_index(drop=True)\n",
    "results.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 829.507963,
   "end_time": "2022-12-06T15:45:36.333262",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-06T15:31:46.825299",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
